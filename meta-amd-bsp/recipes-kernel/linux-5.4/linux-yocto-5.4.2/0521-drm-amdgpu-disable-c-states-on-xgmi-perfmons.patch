From bbcd516799bd5d32f38844404390f353bb4c6fd3 Mon Sep 17 00:00:00 2001
From: Jonathan Kim <jonathan.kim@amd.com>
Date: Wed, 16 Oct 2019 20:40:08 -0400
Subject: [PATCH 0521/1453] drm/amdgpu: disable c-states on xgmi perfmons

read or writes to df registers when gpu df is in c-states will result in
hang.  df c-states should be disabled prior to read or writes then
re-enabled after read or writes.

Change-Id: I6d5a83e4fe13e29c73dfb03a94fe7c611e867fec
Signed-off-by: Jonathan Kim <jonathan.kim@amd.com>
Reviewed-by: Evan Quan <Evan.Quan@amd.com>
---
 drivers/gpu/drm/amd/amdgpu/df_v3_6.c | 36 +++++++++++++++++++++++++++-
 1 file changed, 35 insertions(+), 1 deletion(-)

diff --git a/drivers/gpu/drm/amd/amdgpu/df_v3_6.c b/drivers/gpu/drm/amd/amdgpu/df_v3_6.c
index 16fbd2bc8ad1..f403c62c944e 100644
--- a/drivers/gpu/drm/amd/amdgpu/df_v3_6.c
+++ b/drivers/gpu/drm/amd/amdgpu/df_v3_6.c
@@ -93,6 +93,21 @@ const struct attribute_group *df_v3_6_attr_groups[] = {
 		NULL
 };
 
+static df_v3_6_set_df_cstate(struct amdgpu_device *adev, int allow)
+{
+	int r = 0;
+
+	if (is_support_sw_smu(adev)) {
+		r = smu_set_df_cstate(&adev->smu, allow);
+	} else if (adev->powerplay.pp_funcs
+			&& adev->powerplay.pp_funcs->set_df_cstate) {
+		r = adev->powerplay.pp_funcs->set_df_cstate(
+			adev->powerplay.pp_handle, allow);
+	}
+
+	return r;
+}
+
 static uint64_t df_v3_6_get_fica(struct amdgpu_device *adev,
 				 uint32_t ficaa_val)
 {
@@ -102,6 +117,9 @@ static uint64_t df_v3_6_get_fica(struct amdgpu_device *adev,
 	address = adev->nbio.funcs->get_pcie_index_offset(adev);
 	data = adev->nbio.funcs->get_pcie_data_offset(adev);
 
+	if (df_v3_6_set_df_cstate(adev, DF_CSTATE_DISALLOW))
+		return 0xFFFFFFFFFFFFFFFF;
+
 	spin_lock_irqsave(&adev->pcie_idx_lock, flags);
 	WREG32(address, smnDF_PIE_AON_FabricIndirectConfigAccessAddress3);
 	WREG32(data, ficaa_val);
@@ -114,6 +132,8 @@ static uint64_t df_v3_6_get_fica(struct amdgpu_device *adev,
 
 	spin_unlock_irqrestore(&adev->pcie_idx_lock, flags);
 
+	df_v3_6_set_df_cstate(adev, DF_CSTATE_ALLOW);
+
 	return (((ficadh_val & 0xFFFFFFFFFFFFFFFF) << 32) | ficadl_val);
 }
 
@@ -125,6 +145,9 @@ static void df_v3_6_set_fica(struct amdgpu_device *adev, uint32_t ficaa_val,
 	address = adev->nbio.funcs->get_pcie_index_offset(adev);
 	data = adev->nbio.funcs->get_pcie_data_offset(adev);
 
+	if (df_v3_6_set_df_cstate(adev, DF_CSTATE_DISALLOW))
+		return;
+
 	spin_lock_irqsave(&adev->pcie_idx_lock, flags);
 	WREG32(address, smnDF_PIE_AON_FabricIndirectConfigAccessAddress3);
 	WREG32(data, ficaa_val);
@@ -134,8 +157,9 @@ static void df_v3_6_set_fica(struct amdgpu_device *adev, uint32_t ficaa_val,
 
 	WREG32(address, smnDF_PIE_AON_FabricIndirectConfigAccessDataHi3);
 	WREG32(data, ficadh_val);
-
 	spin_unlock_irqrestore(&adev->pcie_idx_lock, flags);
+
+	df_v3_6_set_df_cstate(adev, DF_CSTATE_ALLOW);
 }
 
 /*
@@ -153,12 +177,17 @@ static void df_v3_6_perfmon_rreg(struct amdgpu_device *adev,
 	address = adev->nbio.funcs->get_pcie_index_offset(adev);
 	data = adev->nbio.funcs->get_pcie_data_offset(adev);
 
+	if (df_v3_6_set_df_cstate(adev, DF_CSTATE_DISALLOW))
+		return;
+
 	spin_lock_irqsave(&adev->pcie_idx_lock, flags);
 	WREG32(address, lo_addr);
 	*lo_val = RREG32(data);
 	WREG32(address, hi_addr);
 	*hi_val = RREG32(data);
 	spin_unlock_irqrestore(&adev->pcie_idx_lock, flags);
+
+	df_v3_6_set_df_cstate(adev, DF_CSTATE_ALLOW);
 }
 
 /*
@@ -175,12 +204,17 @@ static void df_v3_6_perfmon_wreg(struct amdgpu_device *adev, uint32_t lo_addr,
 	address = adev->nbio.funcs->get_pcie_index_offset(adev);
 	data = adev->nbio.funcs->get_pcie_data_offset(adev);
 
+	if (df_v3_6_set_df_cstate(adev, DF_CSTATE_DISALLOW))
+		return;
+
 	spin_lock_irqsave(&adev->pcie_idx_lock, flags);
 	WREG32(address, lo_addr);
 	WREG32(data, lo_val);
 	WREG32(address, hi_addr);
 	WREG32(data, hi_val);
 	spin_unlock_irqrestore(&adev->pcie_idx_lock, flags);
+
+	df_v3_6_set_df_cstate(adev, DF_CSTATE_ALLOW);
 }
 
 /* get the number of df counters available */
-- 
2.17.1

